{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n",
      "leftagain\n",
      "right\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "import cv2                 # working with, mainly resizing, images\n",
    "import numpy as np         # dealing with arrays\n",
    "import os                  # dealing with directories\n",
    "from random import shuffle\n",
    "IMG_SIZE = 96\n",
    "LR = 1e-3  #.001 learing rate\n",
    "\n",
    "nb_classes=28\n",
    "\n",
    "MODEL_NAME = 'handsign.model'\n",
    "\n",
    "path='data'\n",
    "\n",
    "IMG_SIZE = 96\n",
    "\n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    label=0\n",
    "    for (dirpath,dirnames,filenames) in os.walk(path):\n",
    "        for dirname in dirnames:\n",
    "            print(dirname)\n",
    "            for(direcpath,direcnames,files) in os.walk(path+\"/\"+dirname):\n",
    "                for file in files:\n",
    "                        actual_path=path+\"/\"+dirname+\"/\"+file\n",
    "                       \n",
    "                        # label=label_img(dirname)\n",
    "                        path1 =path+\"/\"+dirname+'/'+file\n",
    "                        img=cv2.imread(path1,cv2.IMREAD_GRAYSCALE)\n",
    "                        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "                        training_data.append([np.array(img),label])\n",
    "            label=label+1\n",
    "    shuffle(training_data)\n",
    "    return training_data\n",
    "\n",
    "train_data = create_train_data()\n",
    "# test_data = np.load('test_data.npy',encoding=\"latin1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:]\n",
    "test = train_data[:100]\n",
    "\n",
    "##print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traindatlen:1872\n",
      "testdatalen:100\n"
     ]
    }
   ],
   "source": [
    "def one_hot_targets_(labels_dense,nb_classes):\n",
    "    targets = np.array(Y).reshape(-1)\n",
    "    print(targets)\n",
    "    one_hot_targets = np.eye(nb_classes)[targets]\n",
    "    return one_hot_targets\n",
    "\n",
    "print('traindatlen:'+str(len(train)))\n",
    "print('testdatalen:'+str(len(test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 1 ... 3 0 0]\n",
      "val y[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "len X:1872\n",
      "len Y:1872\n"
     ]
    }
   ],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "Y1=one_hot_targets_(Y,nb_classes)\n",
    "# \n",
    "# print('max y'+str(max(Y)))\n",
    "# print('min y'+str(min(Y)))\n",
    "print('val y'+str(Y1))\n",
    "print('len X:'+str(len(X)))\n",
    "print('len Y:'+str(len(Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 1 ... 3 0 0]\n",
      "test_x:100\n",
      "test_y:1872\n",
      "val y[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]\n",
    "test_y1=one_hot_targets_(test_y,nb_classes)\n",
    "test_y=test_y1\n",
    "Y=Y1\n",
    "print('test_x:'+str(len(test_x)))\n",
    "print('test_y:'+str(len(test_y)))\n",
    "print('val y'+str(test_y1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 96\n",
    "LR = 1e-3\n",
    "\n",
    "nb_classes=28\n",
    "\n",
    "MODEL_NAME = 'handsign.model'\n",
    "def cnn_model():\n",
    "\tconvnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "\tconvnet = conv_2d(convnet, 8, 5, activation='relu')\n",
    "\tconvnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "\tconvnet = conv_2d(convnet, 16, 5, activation='relu')\n",
    "\tconvnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "\tconvnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "\tconvnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "\tconvnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "\tconvnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "\tconvnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "\tconvnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "\tconvnet = fully_connected(convnet, 1024, activation='relu')\n",
    "\tconvnet = dropout(convnet, 0.8)\n",
    "\n",
    "\tconvnet = fully_connected(convnet, nb_classes, activation='softmax')\n",
    "\tconvnet = regression(convnet, optimizer='adam', learning_rate=0.01, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "\tmodel = tflearn.DNN(convnet, tensorboard_dir='log')\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.04867\u001b[0m\u001b[0m | time: 5.444s\n",
      "| Adam | epoch: 015 | loss: 0.04867 - acc: 0.9900 -- iter: 1856/1872\n",
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.05070\u001b[0m\u001b[0m | time: 6.628s\n",
      "| Adam | epoch: 015 | loss: 0.05070 - acc: 0.9895 | val_loss: 0.48710 - val_acc: 0.9500 -- iter: 1872/1872\n",
      "--\n",
      "INFO:tensorflow:C:\\Users\\hp\\image_classification\\handsign.model is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Test accuarcy: 95.0000%\n"
     ]
    }
   ],
   "source": [
    "model=cnn_model()\n",
    "\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch=15, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
    "\n",
    "model.save(MODEL_NAME)\n",
    "\n",
    "score = model.evaluate(test_x, test_y)\n",
    "print('Test accuarcy: %0.4f%%' % (score[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "2 down\n",
      "2 down\n",
      "2 down\n",
      "0 left\n",
      "3 right\n",
      "0 left\n",
      "3 right\n",
      "3 right\n",
      "3 right\n",
      "3 right\n",
      "0 left\n",
      "3 right\n",
      "3 right\n",
      "3 right\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "3 right\n",
      "3 right\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "1 stop\n",
      "3 right\n",
      "2 down\n",
      "2 down\n",
      "0 left\n",
      "3 right\n",
      "3 right\n",
      "3 right\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "1 stop\n",
      "2 down\n",
      "2 down\n",
      "2 down\n",
      "2 down\n",
      "2 down\n",
      "2 down\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "2 down\n",
      "2 down\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "2 down\n",
      "2 down\n",
      "2 down\n",
      "2 down\n",
      "2 down\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "0 left\n",
      "2 down\n",
      "2 down\n",
      "2 down\n",
      "2 down\n",
      "2 down\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 96\n",
    "LR = 1e-3\n",
    "\n",
    "nb_classes=28\n",
    "\n",
    "\n",
    "# organize imports\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import time\n",
    "\n",
    "out_label=['left','stop','down','right']\n",
    "\n",
    "\n",
    "pre=[]\n",
    "\n",
    "s=''\n",
    "cchar=[0,0]\n",
    "c1=''\n",
    "\n",
    "# initialize weight for running average\n",
    "aWeight = 0.5\n",
    "\n",
    "# get the reference to the webcam\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# region of interest (ROI) coordinates\n",
    "top, right, bottom, left = 170, 150, 425, 450\n",
    "\n",
    "# initialize num of frames\n",
    "num_frames = 0\n",
    "\n",
    "flag=0\n",
    "flag1=0\n",
    "\n",
    "# keep looping, until interrupted\n",
    "while(True):\n",
    "    # get the current frame\n",
    "    (grabbed, frame) = camera.read()\n",
    "\n",
    "    # resize the frame\n",
    "    frame = imutils.resize(frame, width=700)\n",
    "\n",
    "    # flip the frame so that it is not the mirror view\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # clone the frame\n",
    "    clone = frame.copy()\n",
    "\n",
    "    # get the height and width of the frame\n",
    "    (height, width) = frame.shape[:2]\n",
    "\n",
    "    # get the ROI\n",
    "    roi = frame[top:bottom, right:left]\n",
    "\n",
    "    # convert the roi to grayscale and blur it\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "    \n",
    "    # cv2.drawContours(clone, [segmented + (right, top)], -1, (0, 0, 255))\n",
    "    \n",
    "    img=gray\n",
    "    # img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # img=cv2.imread(\"240fn.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "    # img=cv2.cvtColor(bw_image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "    test_data =img\n",
    "\n",
    "    orig = img\n",
    "    data = img.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "    #model_out = model.predict([data])[0]\n",
    "    model_out = model.predict([data])[0]\n",
    "    # print(model_out)\n",
    "    model_out = model.predict([data])[0]\n",
    "        # print(model_out)\n",
    "    pnb=np.argmax(model_out)\n",
    "    print(str(np.argmax(model_out))+\" \"+str(out_label[pnb]))\n",
    "\n",
    "    pre.append(out_label[pnb]) \n",
    "\n",
    "\n",
    "    cv2.putText(clone,\n",
    "           '%s ' % (str(out_label[pnb])),\n",
    "           (450, 150), cv2.FONT_HERSHEY_PLAIN,5,(0, 255, 0))\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    # draw the segmented hand\n",
    "    cv2.rectangle(clone, (left, top), (right, bottom), (0,255,0), 2)\n",
    "\n",
    "    cv2.putText(clone,\n",
    "                   '%s ' % (str(s)),\n",
    "                   (10, 60), cv2.FONT_HERSHEY_PLAIN,3,(0, 0, 0))\n",
    "\n",
    "    # increment the number of frames\n",
    "    num_frames += 1\n",
    "    # time.sleep(.3)\n",
    "    # display the frame with segmented hand\n",
    "    cv2.imshow(\"Video Feed\", clone)\n",
    "\n",
    "    # observe the keypress by the user\n",
    "    keypress = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the user pressed \"q\", then stop looping\n",
    "    if keypress == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "\n",
    "# free up memory\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
